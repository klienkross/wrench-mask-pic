# wrench-mask-pic
简介：使用奇怪的方法跑一个自动控制表情的面具

主播的脑袋空空的，简述一下先（怎么写的跟实验报告一样，不管了）（Don't read me是吧）

> 感谢deepseek与草酸艾司西酞普兰的大力协助！

 ## 原理简述：

 输入：可以个人化调整位置的形变传感器

 输出：WS2812B LED灯带，显示简单的颜文字

 传感器布局：
 * 颧肌： 微笑/大笑时向上向后牵拉脸颊，压迫面具侧颊区域。
 * 口轮匝肌： 微笑/噘嘴时活动明显，压迫面具嘴周区域（上唇上方、嘴角外侧）。
 * 皱眉肌/降眉间肌： 皱眉/愤怒时，压迫面具眉心、鼻梁上方区域。
 * 眼轮匝肌（外眼角）： 大笑/眯眼时，外眼角皮肤褶皱，可能压迫面具该区域。

 可能的技术路线：
 * 方案1：阈值比较 (最简单)
 * 方案2：距离度量 (更鲁棒)
 * 方案3：轻量级机器学习 KNN/tree/SVM

 ## 实验装备：

 * 可行性验证：
   * 力敏电阻：FSR402
   * 板子：Raspberry Pi Pico
   * LED: WS2812B
   * 电路搭建工具：杜邦线、电阻、电容、面包板等

 * 原型机（还是饼）：
   * 电源：
     * 18650 锂电池 (带保护板， 2000mAh+)
     * TP4056 充电模块 
     * MT3608 升压模块
     * AMS1117 3.3V 稳压模块 (可选)
   * 本体：3D打印（完全不会，可以考虑跟手工up主合作）
   * 焊接工具组（完全不懂，later）

 ## 实验步骤：

 * 可行性验证：
   * 搭建电路：为每个FSR配置分压电路，连接到ADC引脚。
   * 写基础Arduino/Pico代码：读取所有ADC值 -> 串口打印。
   * 测试：将FSR按在脸上不同目标位置（手指模拟面具压力），做表情，观察串口绘图器（Arduino IDE自带）或打印的数值变化。确认目标表情能在目标传感器上产生显著且相对稳定的信号变化！ 这是项目基石。
   * 优化：调整固定电阻值（比如换成22KΩ或47KΩ），观察信号范围和变化灵敏度。目标是让目标表情变化落在ADC量程的中间偏动态范围大的区域。

 * 基础软件框架：
   * 实现“校准模式”：  
   通过串口指令或按钮触发。  
   提示用户（串口输出）做中性脸 -> 记录基线。  
   提示用户做表情A -> 记录数据并存储特征向量 -> 提示做表情B -> ...。  
   将校准数据存储在数组或EEPROM（掉电保存）中。
   * 实现“实时模式”：  
   读取FSR -> 计算 current_delta。  
   实现方案1（阈值）或方案2（距离）的识别逻辑。  
   串口输出识别结果（表情标签）。
   * 核心目标： 在桌面上，通过FSR按在脸上，能让程序可靠地识别出你做的几种预设表情（至少微笑、皱眉）。

 * LED集成与控制：
   * 物料：少量WS2812B灯珠 (如4-8个), 合适电源 (注意电流!)， 可能需要逻辑电平转换器 (如74AHCT125)。
   * 任务：
     * 硬件连接：将LED数据线接到主控板数字引脚，电源独立供电（共地）。
     * 软件：集成Adafruit NeoPixel库或Pico SDK等效库。编写函数控制LED显示不同的静态颜色或简单动画。
     * 修改实时模式代码：根据识别出的表情调用不同的LED显示函数。看到表情->灯光变化的直接反馈
 
 ## 代码结构：

 工作区：vscode

 插件：MicroPython

 